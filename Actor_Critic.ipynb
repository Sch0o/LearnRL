{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T16:39:17.376285Z",
     "start_time": "2025-03-03T16:39:17.266335Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "class MyWrapper(gym.Wrapper):\n",
    "    def __init__(self):\n",
    "        env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self):\n",
    "        state, _ = self.env.reset()\n",
    "        self.step_n = 0\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        done = terminated or truncated\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            done = True\n",
    "        return state, reward, done, info\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "env.reset()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03236017,  0.00699723, -0.02335546, -0.00839442], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T16:39:18.452779Z",
     "start_time": "2025-03-03T16:39:17.377276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import  torch\n",
    "actor_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 2),\n",
    "    torch.nn.Softmax(dim=1),\n",
    ")\n",
    "critic_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 1),\n",
    ")\n",
    "actor_model(torch.randn((2,4))),critic_model(torch.randn((2,4)))"
   ],
   "id": "2d59cebe2b26b21c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4809, 0.5191],\n",
       "         [0.4871, 0.5129]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[-0.0339],\n",
       "         [ 0.0812]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T16:39:18.468678Z",
     "start_time": "2025-03-03T16:39:18.453781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "def get_action(state):\n",
    "    state=torch.FloatTensor(state).reshape(1,4)\n",
    "    probs = actor_model(state)\n",
    "    action=random.choices(range(2), weights=probs[0].tolist(),k=1)[0]\n",
    "    return action\n",
    "get_action([1,2,3,4])"
   ],
   "id": "e3af7cfe9367869b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T16:39:18.484444Z",
     "start_time": "2025-03-03T16:39:18.469180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_oneGame_data():\n",
    "    states=[]\n",
    "    next_states=[]\n",
    "    actions=[]\n",
    "    rewards=[]\n",
    "    overs=[]\n",
    "    state=env.reset()\n",
    "    over=False\n",
    "    while not over:\n",
    "        action=get_action(state)\n",
    "        next_state,reward,over,_=env.step(action)\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        overs.append(over)\n",
    "        next_states.append(next_state)\n",
    "        \n",
    "        state=next_state\n",
    "        \n",
    "    states = torch.tensor(states, dtype=torch.float)\n",
    "    actions = torch.tensor(actions, dtype=torch.long).reshape(-1,1)\n",
    "    rewards = torch.tensor(rewards, dtype=torch.float).reshape(-1,1)\n",
    "    next_states = torch.tensor(next_states,dtype=torch.float)\n",
    "    overs = torch.tensor(overs,dtype=torch.long).reshape(-1,1)\n",
    "\n",
    "    return states, rewards, actions, next_states, overs\n",
    "\n",
    "get_oneGame_data()\n",
    "\n",
    "        "
   ],
   "id": "cc42db65e9a86e46",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schoo\\AppData\\Local\\Temp\\ipykernel_3992\\4149037861.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  states = torch.tensor(states, dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0387, -0.0324,  0.0395,  0.0121],\n",
       "         [-0.0393,  0.1621,  0.0397, -0.2678],\n",
       "         [-0.0361, -0.0335,  0.0344,  0.0371],\n",
       "         [-0.0367,  0.1611,  0.0351, -0.2445],\n",
       "         [-0.0335,  0.3557,  0.0302, -0.5259],\n",
       "         [-0.0264,  0.5504,  0.0197, -0.8089],\n",
       "         [-0.0154,  0.3550,  0.0035, -0.5101],\n",
       "         [-0.0083,  0.1598, -0.0067, -0.2163],\n",
       "         [-0.0051,  0.3550, -0.0110, -0.5111],\n",
       "         [ 0.0020,  0.5503, -0.0212, -0.8072],\n",
       "         [ 0.0130,  0.7457, -0.0374, -1.1065],\n",
       "         [ 0.0279,  0.5511, -0.0595, -0.8258],\n",
       "         [ 0.0389,  0.3569, -0.0760, -0.5524],\n",
       "         [ 0.0461,  0.5530, -0.0871, -0.8680],\n",
       "         [ 0.0571,  0.7491, -0.1044, -1.1868],\n",
       "         [ 0.0721,  0.5555, -0.1282, -0.9285],\n",
       "         [ 0.0832,  0.7521, -0.1467, -1.2586],\n",
       "         [ 0.0983,  0.9488, -0.1719, -1.5934],\n",
       "         [ 0.1172,  1.1455, -0.2038, -1.9344]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " tensor([[1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]]),\n",
       " tensor([[-3.9317e-02,  1.6215e-01,  3.9734e-02, -2.6783e-01],\n",
       "         [-3.6074e-02, -3.3518e-02,  3.4377e-02,  3.7116e-02],\n",
       "         [-3.6744e-02,  1.6110e-01,  3.5119e-02, -2.4453e-01],\n",
       "         [-3.3522e-02,  3.5570e-01,  3.0229e-02, -5.2593e-01],\n",
       "         [-2.6408e-02,  5.5038e-01,  1.9710e-02, -8.0893e-01],\n",
       "         [-1.5401e-02,  3.5500e-01,  3.5318e-03, -5.1012e-01],\n",
       "         [-8.3008e-03,  1.5982e-01, -6.6706e-03, -2.1632e-01],\n",
       "         [-5.1043e-03,  3.5504e-01, -1.0997e-02, -5.1110e-01],\n",
       "         [ 1.9965e-03,  5.5032e-01, -2.1219e-02, -8.0723e-01],\n",
       "         [ 1.3003e-02,  7.4572e-01, -3.7364e-02, -1.1065e+00],\n",
       "         [ 2.7917e-02,  5.5111e-01, -5.9494e-02, -8.2578e-01],\n",
       "         [ 3.8939e-02,  3.5685e-01, -7.6009e-02, -5.5239e-01],\n",
       "         [ 4.6076e-02,  5.5295e-01, -8.7057e-02, -8.6802e-01],\n",
       "         [ 5.7136e-02,  7.4915e-01, -1.0442e-01, -1.1868e+00],\n",
       "         [ 7.2118e-02,  5.5552e-01, -1.2815e-01, -9.2854e-01],\n",
       "         [ 8.3229e-02,  7.5212e-01, -1.4672e-01, -1.2586e+00],\n",
       "         [ 9.8271e-02,  9.4878e-01, -1.7190e-01, -1.5934e+00],\n",
       "         [ 1.1725e-01,  1.1455e+00, -2.0376e-01, -1.9344e+00],\n",
       "         [ 1.4016e-01,  1.3421e+00, -2.4245e-01, -2.2827e+00]]),\n",
       " tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T16:39:18.499884Z",
     "start_time": "2025-03-03T16:39:18.485436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test():\n",
    "    state=env.reset()\n",
    "    reward_sum=0\n",
    "    over=False\n",
    "    while not over:\n",
    "        action=get_action(state)\n",
    "        next_state,reward,over,_=env.step(action)\n",
    "        state=next_state\n",
    "        reward_sum+=reward\n",
    "    return reward_sum\n",
    "test()"
   ],
   "id": "e52328d41e4a3057",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T16:44:35.614401Z",
     "start_time": "2025-03-03T16:44:23.684997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    optimizer = torch.optim.Adam(actor_model.parameters(), lr=1e-3)\n",
    "    optimizer_c=torch.optim.Adam(critic_model.parameters(), lr=1e-2)\n",
    "    loss_fc=torch.nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(1000):\n",
    "        states, rewards, actions, next_states, overs=get_oneGame_data()\n",
    "        \n",
    "        #cirtic\n",
    "        values=critic_model(states)\n",
    "        target=rewards+(1-overs)*0.98*critic_model(next_states).detach()\n",
    "        loss_c=loss_fc(values,target)\n",
    "        \n",
    "        optimizer_c.zero_grad()\n",
    "        loss_c.backward()\n",
    "        optimizer_c.step()\n",
    "        \n",
    "        #actor\n",
    "        probs=actor_model(states)\n",
    "        probs=probs.gather(1,actions)\n",
    "        delta=(target-values).detach()\n",
    "        loss=(-torch.log(probs)*delta).mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 100 == 0:\n",
    "            test_result=sum([test() for _ in range(10) ])/10\n",
    "            print('epoch:',epoch,'test_result:',test_result)\n",
    "        \n",
    "train()"
   ],
   "id": "3244c640c1734b2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 99 test_result: 200.0\n",
      "epoch: 199 test_result: 200.0\n",
      "epoch: 299 test_result: 200.0\n",
      "epoch: 399 test_result: 200.0\n",
      "epoch: 499 test_result: 200.0\n",
      "epoch: 599 test_result: 195.1\n",
      "epoch: 699 test_result: 200.0\n",
      "epoch: 799 test_result: 200.0\n",
      "epoch: 899 test_result: 200.0\n",
      "epoch: 999 test_result: 200.0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T16:39:26.854386Z",
     "start_time": "2025-03-03T16:39:26.840292Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ebd1ad0c8a2c1fe6",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
